{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e032738c",
   "metadata": {},
   "source": [
    "# 1 - Instalando dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f11031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando para usar\n",
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2352b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puxando elas\n",
    "\n",
    "import cv2\n",
    "# Itens do mp normalmente são chamados de soluções - solutions\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "# mp_drawing nos da as utilidades de desenho dos objetos\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# Aqui a gente defini o modelo que vamos usar do mediapipe, pois existem vários, e vamos usar o para pose\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b390546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando a câmera\n",
    "\n",
    "# Pegando o vídeo de alguma câmera conectada, a primeira - 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "  # Ret é só o retorno, nada útil por agora\n",
    "  # Frame é o frame mesmo, o que nos mostra\n",
    "  ret, frame = cap.read()\n",
    "  # Aqui o primeiro é o nome da caixa que temos o frame(vídeo), e o segundo o que mostramos\n",
    "  cv2.imshow(\"Treinador de Academia Personalizado\", frame)\n",
    "\n",
    "  if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b35371",
   "metadata": {},
   "source": [
    "# 2 - Fazendo Detecções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando o vídeo de alguma câmera conectada, a primeira - 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Criando uma nova instância do pose do mediapipe definindo que o mínimo de confidência de detecção como 50%\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        # Ret é só o retorno, nada útil por agora\n",
    "        # Frame é o frame mesmo, o que nos mostra\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Mudando a cor da imagem, pois fica melhor para o mediapipe, mandando na ordem certa, e transformando em RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Fazendo detecções\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        # Recolorindo para mostrar a imagem to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Rederizando as detecções\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, \n",
    "                                  # Mudando a cor dos pontos, primeiro dos pontos\n",
    "                                  mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2), \n",
    "                                  # Aqui das conexões\n",
    "                                  mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                                  )\n",
    "\n",
    "        # Aqui o primeiro é o nome da caixa que temos o frame(vídeo), e o segundo o que mostramos\n",
    "        cv2.imshow(\"Treinador de Academia Personalizado\", image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f0f41",
   "metadata": {},
   "source": [
    "# 3 - Determinando as juntas\n",
    "\n",
    "Aqui recomendo ver a imagem das juntas que o mediapipe pega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando o vídeo de alguma câmera conectada, a primeira - 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Criando uma nova instância do pose do mediapipe definindo que o mínimo de confidência de detecção como 50%\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        # Ret é só o retorno, nada útil por agora\n",
    "        # Frame é o frame mesmo, o que nos mostra\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Mudando a cor da imagem, pois fica melhor para o mediapipe, mandando na ordem certa, e transformando em RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Fazendo detecções\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        # Recolorindo para mostrar a imagem to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Extraindo os pontos das juntas\n",
    "        # Nem sempre dá certo e elas são visíveis, então fazemos dentro de um try para não quebrar\n",
    "        try: \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            print(landmarks)\n",
    "        except: \n",
    "            print(\"Erro ao pegar as landmarks\")\n",
    "            pass\n",
    "\n",
    "        # Rederizando as detecções\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, \n",
    "                                  # Mudando a cor dos pontos, primeiro dos pontos\n",
    "                                  mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2), \n",
    "                                  # Aqui das conexões\n",
    "                                  mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                                  )\n",
    "\n",
    "        # Aqui o primeiro é o nome da caixa que temos o frame(vídeo), e o segundo o que mostramos\n",
    "        cv2.imshow(\"Treinador de Academia Personalizado\", image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f335c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for landmarkExist in mp_pose.PoseLandmark:\n",
    "    print(landmarkExist, landmarkExist.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cafa037",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose.PoseLandmark.LEFT_SHOULDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73985059",
   "metadata": {},
   "source": [
    "# 4 - Calculando ângulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a) # Primeiro - Ombro\n",
    "    b = np.array(b) # Do meio - Cotovelo\n",
    "    c = np.array(c) # Último - Mão\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "    # Definindo o ângulo como máximo de 180, porque o braço não vai além\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility < 0.9:\n",
    "    print(\"Pouca visibilidade do ombro, impossível calcular\" , landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility)\n",
    "else:\n",
    "    print(\"Legal\", landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62864d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando os valores da posição do ombro\n",
    "shoulder = [\n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, \n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y,\n",
    "            ]\n",
    "\n",
    "# Pegando os valores da posição do cotovelo\n",
    "elbow = [\n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, \n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,\n",
    "            ]\n",
    "\n",
    "# Pegando os valores da posição da mão\n",
    "wrist = [\n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, \n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y,\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shoulder)\n",
    "print(elbow)\n",
    "print(wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b90f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o ângulo do braço\n",
    "calculate_angle(shoulder, elbow, wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "hipTest = [\n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, \n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y,\n",
    "            ]\n",
    "\n",
    "shoulderTest = [\n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, \n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y,\n",
    "            ]\n",
    "\n",
    "wristTest = [\n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, \n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hipTest, shoulderTest, wristTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dcc460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a distância do corpo entre outros itens, apenas mostrando que da pra fazer\n",
    "calculate_angle(hipTest, shoulderTest, wristTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22641153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando as coordenadas normalizada pelo tamanho da imagem, nesse caso, com uma webcam de 640x480\n",
    "tuple(np.multiply(elbow, [640, 480]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f2f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando o tamanho da webcam de forma dinâmica em pixels para passar pro np.multiply\n",
    "largura = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "altura = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "print(f\"Resolução atual: {int(largura)}x{int(altura)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537778ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando as posições do ângulo no vídeo e colocando no frame\n",
    "\n",
    "# Pegando o vídeo de alguma câmera conectada, a primeira - 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Criando uma nova instância do pose do mediapipe definindo que o mínimo de confidência de detecção como 50%\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        largura = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        altura = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "        print(f\"Resolução atual: {int(largura)}x{int(altura)}\")\n",
    "\n",
    "        # Ret é só o retorno, nada útil por agora\n",
    "        # Frame é o frame mesmo, o que nos mostra\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Mudando a cor da imagem, pois fica melhor para o mediapipe, mandando na ordem certa, e transformando em RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Fazendo detecções\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        # Recolorindo para mostrar a imagem to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Extraindo os pontos das juntas\n",
    "        # Nem sempre dá certo e elas são visíveis, então fazemos dentro de um try para não quebrar\n",
    "        try: \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Pegando as coordenadas\n",
    "            # Poderiamos fazer como fizemos a cima com outros pontos para calcular\n",
    "            shoulder = [ landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, \n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y,\n",
    "                        ]\n",
    "            elbow = [ landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, \n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,\n",
    "                        ]\n",
    "            wrist = [ landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, \n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y,\n",
    "                        ]\n",
    "            \n",
    "            # Calculando o ângulo\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "\n",
    "            # Visualizando o ângulo\n",
    "            cv2.putText(image, \n",
    "                str(angle), \n",
    "                tuple(np.multiply(elbow, [int(largura), int(altura)]).astype(int)), \n",
    "                # A partir daqui, apenas mexemos no texto\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, \n",
    "                (255, 255, 255), \n",
    "                2, \n",
    "                cv2.LINE_AA,\n",
    "                )\n",
    "        except: \n",
    "            print(\"Erro ao pegar as landmarks\")\n",
    "            pass\n",
    "\n",
    "        # Rederizando as detecções\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, \n",
    "                                  # Mudando a cor dos pontos, primeiro dos pontos\n",
    "                                  mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2), \n",
    "                                  # Aqui das conexões\n",
    "                                  mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                                  )\n",
    "\n",
    "        # Aqui o primeiro é o nome da caixa que temos o frame(vídeo), e o segundo o que mostramos\n",
    "        cv2.imshow(\"Treinador de Academia Personalizado\", image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e51cce",
   "metadata": {},
   "source": [
    "# 4 - Criando o contador de curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando as posições do ângulo no vídeo e colocando no frame\n",
    "\n",
    "# Pegando o vídeo de alguma câmera conectada, a primeira - 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Variáveis para o contador\n",
    "counter = 0\n",
    "stage = None\n",
    "\n",
    "# Criando uma nova instância do pose do mediapipe definindo que o mínimo de confidência de detecção como 50%\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        largura = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        altura = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "        # Ret é só o retorno, nada útil por agora\n",
    "        # Frame é o frame mesmo, o que nos mostra\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Mudando a cor da imagem, pois fica melhor para o mediapipe, mandando na ordem certa, e transformando em RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Fazendo detecções\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        # Recolorindo para mostrar a imagem to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Extraindo os pontos das juntas\n",
    "        # Nem sempre dá certo e elas são visíveis, então fazemos dentro de um try para não quebrar\n",
    "        try: \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Pegando as coordenadas\n",
    "            # Poderiamos fazer como fizemos a cima com outros pontos para calcular\n",
    "            shoulder = [ landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, \n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y,\n",
    "                        ]\n",
    "            elbow = [ landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, \n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,\n",
    "                        ]\n",
    "            wrist = [ landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, \n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y,\n",
    "                        ]\n",
    "            \n",
    "            # Calculando o ângulo\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "\n",
    "            # Visualizando o ângulo\n",
    "            cv2.putText(image, \n",
    "                str(angle), \n",
    "                tuple(np.multiply(elbow, [int(largura), int(altura)]).astype(int)), \n",
    "                # A partir daqui, apenas mexemos no texto\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, \n",
    "                (255, 255, 255), \n",
    "                2, \n",
    "                cv2.LINE_AA,\n",
    "                )\n",
    "            \n",
    "            # Criando a lógica para o contador\n",
    "            if angle > 160:\n",
    "                stage = \"down\"\n",
    "            if angle < 30 and stage == \"down\":\n",
    "                stage = \"up\"\n",
    "                counter += 1\n",
    "                print(counter)\n",
    "        except: \n",
    "            print(\"Erro ao pegar as landmarks\")\n",
    "            pass\n",
    "\n",
    "        # Renderizando o contador\n",
    "        # Criando uma caixa\n",
    "        cv2.rectangle(image, \n",
    "                      (0, 0), \n",
    "                      (225, 73), \n",
    "                      (245, 117, 16), \n",
    "                      -1,\n",
    "                      )\n",
    "\n",
    "        # Colocando os dados\n",
    "        cv2.putText(image, \n",
    "                    \"Reps\", \n",
    "                    (15, 12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.5, \n",
    "                    (0, 0, 0), \n",
    "                    1, \n",
    "                    cv2.LINE_AA,\n",
    "                    )\n",
    "        cv2.putText(image, \n",
    "                    str(counter), \n",
    "                    (10, 60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    2, \n",
    "                    (255, 255, 255), \n",
    "                    2, \n",
    "                    cv2.LINE_AA,\n",
    "                    )\n",
    "        \n",
    "        # Colocando o estado\n",
    "        cv2.putText(image, \n",
    "                    \"Estado\", \n",
    "                    (65, 12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.5, \n",
    "                    (0, 0, 0), \n",
    "                    1, \n",
    "                    cv2.LINE_AA,\n",
    "                    )\n",
    "        cv2.putText(image, \n",
    "                    stage, \n",
    "                    (60, 60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    2, \n",
    "                    (255, 255, 255), \n",
    "                    2, \n",
    "                    cv2.LINE_AA,\n",
    "                    )\n",
    "\n",
    "        # Rederizando as detecções\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, \n",
    "                                  # Mudando a cor dos pontos, primeiro dos pontos\n",
    "                                  mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2), \n",
    "                                  # Aqui das conexões\n",
    "                                  mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                                  )\n",
    "\n",
    "        # Aqui o primeiro é o nome da caixa que temos o frame(vídeo), e o segundo o que mostramos\n",
    "        cv2.imshow(\"Treinador de Academia Personalizado\", image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
